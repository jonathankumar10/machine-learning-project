{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'train_dataset/'\n",
    "name = os.listdir(path)\n",
    "folder_name = ['1','2','3','4','5','6','7','8','9','10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a folder for all of the reviews based on it's rating from 1 to 10 for training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,10):\n",
    "    if not os.path.exists(path +folder_name[x]):\n",
    "        os.makedirs(path+folder_name[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting each text file into a directory according to it's review rating for training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in name:\n",
    "    if \"*_1.txt\" in file and not os.path.exists(path +'1/' +file):\n",
    "        shutil.move(path+file, path +'1/' +file)\n",
    "    if \"*_2.txt\" in file and not os.path.exists(path +'2/' +file):\n",
    "        shutil.move(path+file, path +'2/' +file)\n",
    "    if \"*_3.txt\" in file and not os.path.exists(path +'3/' +file):\n",
    "        shutil.move(path+file, path +'3/' +file)\n",
    "    if \"*_4.txt\" in file and not os.path.exists(path +'4/' +file):\n",
    "        shutil.move(path+file, path +'4/' +file)\n",
    "    if \"*_5.txt\" in file and not os.path.exists(path +'5/' +file):\n",
    "        shutil.move(path+file, path +'5/' +file)\n",
    "    if \"*_6.txt\" in file and not os.path.exists(path +'6/' +file):\n",
    "        shutil.move(path+file, path +'6/' +file)\n",
    "    if \"*_7.txt\" in file and not os.path.exists(path +'7/' +file):\n",
    "        shutil.move(path+file, path +'7/' +file)\n",
    "    if \"*_8.txt\" in file and not os.path.exists(path +'8/' +file):\n",
    "        shutil.move(path+file, path +'8/' +file)\n",
    "    if \"*_9.txt\" in file and not os.path.exists(path +'9/' +file):\n",
    "        shutil.move(path+file, path +'9/' +file)\n",
    "    if \"*_10.txt\" in file and not os.path.exists(path +'10/' +file):\n",
    "        shutil.move(path+file, path +'10/' +file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test_dataset/'\n",
    "name = os.listdir(path)\n",
    "folder_name = ['1','2','3','4','5','6','7','8','9','10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a folder for all of the reviews based on it's rating from 1 to 10 for testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,10):\n",
    "    if not os.path.exists(path +folder_name[x]):\n",
    "        os.makedirs(path+folder_name[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting each text file into a directory according to it's review rating for training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in name:\n",
    "    if \"*_1.txt\" in file and not os.path.exists(path +'1/' +file):\n",
    "        shutil.move(path+file, path +'1/' +file)\n",
    "    if \"*_2.txt\" in file and not os.path.exists(path +'2/' +file):\n",
    "        shutil.move(path+file, path +'2/' +file)\n",
    "    if \"*_3.txt\" in file and not os.path.exists(path +'3/' +file):\n",
    "        shutil.move(path+file, path +'3/' +file)\n",
    "    if \"*_4.txt\" in file and not os.path.exists(path +'4/' +file):\n",
    "        shutil.move(path+file, path +'4/' +file)\n",
    "    if \"*_5.txt\" in file and not os.path.exists(path +'5/' +file):\n",
    "        shutil.move(path+file, path +'5/' +file)\n",
    "    if \"*_6.txt\" in file and not os.path.exists(path +'6/' +file):\n",
    "        shutil.move(path+file, path +'6/' +file)\n",
    "    if \"*_7.txt\" in file and not os.path.exists(path +'7/' +file):\n",
    "        shutil.move(path+file, path +'7/' +file)\n",
    "    if \"*_8.txt\" in file and not os.path.exists(path +'8/' +file):\n",
    "        shutil.move(path+file, path +'8/' +file)\n",
    "    if \"*_9.txt\" in file and not os.path.exists(path +'9/' +file):\n",
    "        shutil.move(path+file, path +'9/' +file)\n",
    "    if \"*_10.txt\" in file and not os.path.exists(path +'10/' +file):\n",
    "        shutil.move(path+file, path +'10/' +file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('train_dataset/train_dataset_1.csv')\n",
    "df2 = pd.read_csv('train_dataset/train_dataset_2.csv')\n",
    "df3 = pd.read_csv('train_dataset/train_dataset_3.csv')\n",
    "df4 = pd.read_csv('train_dataset/train_dataset_4.csv')\n",
    "df5 = pd.read_csv('train_dataset/train_dataset_5.csv')\n",
    "df6 = pd.read_csv('train_dataset/train_dataset_6.csv')\n",
    "df7 = pd.read_csv('train_dataset/train_dataset_7.csv')\n",
    "df8 = pd.read_csv('train_dataset/train_dataset_8.csv')\n",
    "df9 = pd.read_csv('train_dataset/train_dataset_9.csv')\n",
    "df10 = pd.read_csv('train_dataset/train_dataset_10.csv')\n",
    "\n",
    "# df11 = pd.read_csv('test_dataset/test_dataset_1.csv')\n",
    "# df12 = pd.read_csv('test_dataset/test_dataset_2.csv')\n",
    "# df13 = pd.read_csv('test_dataset/test_dataset_3.csv')\n",
    "# df14 = pd.read_csv('test_dataset/test_dataset_4.csv')\n",
    "# df15 = pd.read_csv('test_dataset/test_dataset_5.csv')\n",
    "# df16 = pd.read_csv('test_dataset/test_dataset_6.csv')\n",
    "# df17 = pd.read_csv('test_dataset/test_dataset_7.csv')\n",
    "# df18 = pd.read_csv('test_dataset/test_dataset_8.csv')\n",
    "# df19 = pd.read_csv('test_dataset/test_dataset_9.csv')\n",
    "# df20 = pd.read_csv('test_dataset/test_dataset_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column for the current class for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Class'] = '1'\n",
    "df2['Class'] = '2'\n",
    "df3['Class'] = '3'\n",
    "df4['Class'] = '4'\n",
    "df5['Class'] = '5'\n",
    "df6['Class'] = '6'\n",
    "df7['Class'] = '7'\n",
    "df8['Class'] = '8'\n",
    "df9['Class'] = '9'\n",
    "df10['Class'] = '10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate given Dataframes into a single unified Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]\n",
    "dataset = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Source information column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataset['Source.Name']  (Only to be done once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_excel('final_train_dataset.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
