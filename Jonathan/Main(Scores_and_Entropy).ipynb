{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train_dataset/final_train_dataset.csv')\n",
    "test_data = pd.read_csv('./data/test_dataset/final_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is mediocre at best. Angie Harmon is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film is one giant pant load. Paul Schrade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie must be in line for the most boring...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Class\n",
       "0  Sorry everyone,,, I know this is supposed to b...      1\n",
       "1  When I was little my parents took me along to ...      1\n",
       "2  This film is mediocre at best. Angie Harmon is...      1\n",
       "3  This film is one giant pant load. Paul Schrade...      1\n",
       "4  This movie must be in line for the most boring...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Change column names to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = train_data.columns.str.lower()\n",
    "test_data.columns = test_data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Checking for null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews    False\n",
       "class      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lowercase all review data,  Removing all punctuations, Removing words with numbers,  Remove Tags and Html Tags, Tokenization, Removing Stopwords and  Parts of speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def data_cleaning(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    words = text.split()\n",
    "    table = str.maketrans(\"\",\"\",string.punctuation)\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    text = \" \".join(stripped)\n",
    "\n",
    "    text = re.sub('\\w*\\d\\w*', \"\",text)\n",
    "\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    text = re.sub(cleanr, '', text)\n",
    "\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "    text = tokenizer.tokenize(text)\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    \n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data['clean_reviews'] = train_data['reviews'].apply(data_cleaning)\n",
    "test_data['clean_reviews'] = test_data['reviews'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check scores and Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def sentimentAnalysis(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return(score)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "def text_entropy(text):\n",
    "    # we only consider UTF8 characters to compute the text entropy\n",
    "    pk = [text.count(chr(i)) for i in range(256)]\n",
    "    if sum(pk) == 0:\n",
    "        text_entropy = None\n",
    "    else:\n",
    "        text_entropy = entropy(pk, base=2)\n",
    "    return text_entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data['scores'] =  train_data['clean_reviews'].apply(sentimentAnalysis)\n",
    "train_data =pd.concat([train_data.drop(['scores'], axis=1), train_data['scores'].apply(pd.Series)], axis=1)\n",
    "\n",
    "\n",
    "test_data['scores'] =  test_data['clean_reviews'].apply(sentimentAnalysis)\n",
    "test_data =pd.concat([test_data.drop(['scores'], axis=1), test_data['scores'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data['entropy'] =  train_data['clean_reviews'].apply(text_entropy)\n",
    "test_data['entropy'] =  test_data['clean_reviews'].apply(text_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below done to re arrange the columns\n",
    "\n",
    "# only run it when its the first time the model \n",
    "\n",
    "cols = list(train_data.columns)\n",
    "cols2 = list(test_data.columns)\n",
    "cols = [cols[0]]+[cols[2]]+[cols[3]]+[cols[4]]+[cols[5]]+[cols[6]]+[cols[7]]+[cols[1]]\n",
    "cols2 = [cols2[0]]+[cols2[2]]+[cols2[3]]+[cols2[4]]+[cols2[5]]+[cols2[6]]+[cols2[7]]+[cols2[1]]\n",
    "train_data = train_data[cols]\n",
    "test_data = test_data[cols2]\n",
    "del train_data['clean_reviews']\n",
    "del train_data['reviews']\n",
    "del test_data['clean_reviews']\n",
    "del test_data['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.9655</td>\n",
       "      <td>4.221264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.5143</td>\n",
       "      <td>4.115131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.9427</td>\n",
       "      <td>4.169845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>4.219201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>4.150576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>4.201828</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>4.132807</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>4.235828</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>4.149199</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>4.176519</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         neg    neu    pos  compound   entropy  class\n",
       "0      0.250  0.627  0.123   -0.9655  4.221264      1\n",
       "1      0.207  0.633  0.160   -0.5143  4.115131      1\n",
       "2      0.297  0.503  0.200   -0.9427  4.169845      1\n",
       "3      0.095  0.688  0.217    0.8033  4.219201      1\n",
       "4      0.190  0.628  0.182   -0.1027  4.150576      1\n",
       "...      ...    ...    ...       ...       ...    ...\n",
       "24995  0.028  0.583  0.390    0.9928  4.201828     10\n",
       "24996  0.018  0.596  0.386    0.9896  4.132807     10\n",
       "24997  0.044  0.682  0.274    0.9969  4.235828     10\n",
       "24998  0.044  0.613  0.343    0.9718  4.149199     10\n",
       "24999  0.059  0.634  0.307    0.9705  4.176519     10\n",
       "\n",
       "[25000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling up all the missing values in the procssed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['entropy'] = train_data['entropy'].fillna(0)\n",
    "test_data['entropy'] = test_data['entropy'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you need to save data to file uncomment the following line of code\n",
    "\n",
    "# train_data.to_csv('./train_dataset/scoreAndPolarity_train_data.csv', header=True, index = False)\n",
    "# test_data.to_csv('./test_dataset/scoreAndPolarity_test_data.csv', header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg         False\n",
       "neu         False\n",
       "pos         False\n",
       "compound    False\n",
       "entropy     False\n",
       "class       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/train_dataset/scoreAndPolarity_train_data.csv')\n",
    "df2 = pd.read_csv('./data/test_dataset/scoreAndPolarity_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Implementing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(y_pred, y_prob):\n",
    "    acc = accuracy_score(df2[\"class\"], y_pred)\n",
    "    # Result\n",
    "    print(\"Accuracy: {:.2f}\".format(acc*100),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = df1.iloc[0:,0:5]\n",
    "train_labels = df1.iloc[0:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = df2.iloc[0:,0:5]\n",
    "test_labels = df2.iloc[0:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating mean sqaured error of the model computing the test label values to the test predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.59252"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_labels,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/test_dataset/cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediciton of a Review from the test dataset and spitting out a value from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like to think of myself as a bad movie connoisseur. I like to think that the films most people label as the worst of all time I can easily withstand.<br /><br />But...there are exceptions. I can only recall three movies I have had the misfortune to see that I have repeatedly used the fast-forward button for large chunks of the story. Those movies are The Mighty Gorga, Night of the Seagulls, and this little crap, Deep Blood.<br /><br />In the world of Jaws ripoffs, this falls off the scale. Deep Blood doesn\\'t have the realistic storyline of the original Crocodile, nor the incredible effects of The Sea Serpent, nor the commentary of Tintorera. No, instead we are treated to a handful of teens from any random failed \\'80s public access sitcom battling bullies and the local sheriff.<br /><br />Shark attacks are realized by quick cuts of documentary footage with actors thrashing about in the water, occasionally with a bit of what appears to be orange-ish paint thrown into the water. Not a minute of original shark footage exists in this celluloid waste dump.<br /><br />Normally, I, or somebody like me, would read a dismal review like this one and say \"cool, I gotta find a copy of this!\" That\\'s the same thought I had when I read another viewer\\'s review on this very site. How wrong I was.<br /><br />So...from one bad movie fan to another...let this collect dust on the shelf...grab Up From the Depths or The Great Alligator instead to satisfy your need for something evil lurking in the water.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[1000,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.iloc[14526]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array(test_features.iloc[14526].values.tolist())\n",
    "predict = model.predict(a.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18527441, 0.18066728, 0.18542106, 0.23268639, 0.21595087])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
